{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staying Connected with Interconnect!\n",
    "# Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the project was to train a machine learning model to predict if a client of Interconnect will discontinue their subscription.\n",
    "## Work Plan Execution\n",
    "Of the 5 step work plan stated at the beginning stages of this project, no steps were skipped. Instead, some steps were modified or enhanced.\n",
    "In step 1, I stated that the new column I would create to represent the target would be 1s and 0s. The 1s originally were to represent active clients while 0s would represent churned clients. That ended up being switch to allow the churned client to be the \"positive probability\" when the predict_proba() method was used for each model.\n",
    "Steps 2 and 3 were executed the same. Steps 4 and 5 were to train DecisionTree, RandomForest, and LogisticRegression models while observing the AUC-ROC metric tested on a validation set. Upon failure to reach a desired AUC-ROC value, it was mentioned that adjustments would be made to the features as well as training other models. The model mentioned was KNearest Neighbors, which indeed was used. However, I also trained even more models (CatBoost and SGD Classification) to attempt reaching the highest AUC-ROC value as possible.\n",
    "## Challenges\n",
    "The biggest difficulty I had at first was that my AUC-ROC values were extremely low. After training some models, the value did not exceed about 0.32. I gave it some thought then realized that I needed to switch the target label classification as mentioned earlier. It turns out I was measuring negative probabilities and I needed their complements. It made more sense after because the objective is to observe and predict cancellations. Making that the positive probabilities worked better in my favor. Once the adjustment was made, my AUC-ROC values were much more appealing and comprehensive.\n",
    "The next challenge was getting the AUC-ROC value to a desired number. My goal was to reach 0.85 before using the model on the test set. Scaling numerical data and including a new feature did not allow me to reach it exactly. I did, however, get it very close.\n",
    "## Key Ideas\n",
    "To solve this task, the most important thing is to make sense of what the values mean. Before testing the models, I needed to concat the datasets together. Since they were different sizes, I was left with many missing values. Some numerical data needed to be zero because it made sense in context (e.g. the total charges for people who just joined). Other Categorical data was given a string of 'N/A' because it indeed was not applicable. That allowed for a new category to be interpreted by the model for certain features. Without proper understanding of the given data, training would not have been accurate.\n",
    "## Final Model\n",
    "The final model that provided the best score was a CatBoost model. Specifically one that uses \"Logloss\" as its loss function and uses 120 iterations. Keep in mind that there was an added feature that was created by dividing the total charges by the monthly charges then rounded to the nearest whole number. The numerical data was then scaled with standard scaler.\n",
    "This model was tested on the test set and gave an AUC-ROC score of 0.845!\n",
    "\n",
    "With all of this being said, Interconnect can use this model to identify which customers have most commonalities with those who have left in the past. If the customers indeed have those commonalities, promotional opportunities can be sent to those customers (e.g. discounts, bonus features, etc.). The retention of these customers with a promotional opportunity will surely be monetarily better than the customer leaving overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
