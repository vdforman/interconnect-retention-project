{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 1</b><br><br>\n",
    "\n",
    "  Hi Victor, I‚Äôm <b>Victor Camargo</b>. I‚Äôve reviewed your project and accompanying report ‚Äî and I‚Äôm happy to approve it! You've done an excellent job building a predictive model for churn, and your final CatBoost model reached a strong AUC-ROC of **0.845** ‚Äî very close to the 0.85 target.\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úîÔ∏è Clean and consistent preprocessing across multiple datasets<br>\n",
    "  ‚úîÔ∏è Smart use of OneHotEncoding, feature engineering, and scaling<br>\n",
    "  ‚úîÔ∏è Systematic testing of various models and hyperparameters<br>\n",
    "  ‚úîÔ∏è Clear report that outlines your workflow, challenges, and final solution<br><br>\n",
    "\n",
    "  üü° Suggestions (optional polish only):<br>\n",
    "  ‚Ä¢ In your report, correct a few typos like ‚ÄúSpecfically‚Äù ‚Üí ‚ÄúSpecifically‚Äù and ‚Äúeariler‚Äù ‚Üí ‚Äúearlier‚Äù<br>\n",
    "  ‚Ä¢ In the Final Model section, consider briefly mentioning how this model can be used by Interconnect to guide retention strategies<br><br>\n",
    "\n",
    "\n",
    "  Excellent work ‚Äî approved!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staying Connected with Interconnect!\n",
    "# Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the project was to train a machine learning model to predict if a client of Interconnect will discontinue their subscription.\n",
    "## Work Plan Execution\n",
    "Of the 5 step work plan stated at the beginning stages of this project, no steps were skipped. Instead, some steps were modified or enhanced.\n",
    "In step 1, I stated that the new column I would create to represent the target would be 1s and 0s. The 1s originally were to represent active clients while 0s would represent churned clients. That ended up being switch to allow the churned client to be the \"positive probability\" when the predict_proba() method was used for each model.\n",
    "Steps 2 and 3 were executed the same. Steps 4 and 5 were to train DecisionTree, RandomForest, and LogisticRegression models while observing the AUC-ROC metric tested on a validation set. Upon failure to reach a desired AUC-ROC value, it was mentioned that adjustments would be made to the features as well as training other models. The model mentioned was KNearest Neighbors, which indeed was used. However, I also trained even more models (CatBoost and SGD Classification) to attempt reaching the highest AUC-ROC value as possible.\n",
    "## Challenges\n",
    "The biggest difficulty I had at first was that my AUC-ROC values were extremely low. After training some models, the value did not exceed about 0.32. I gave it some thought then realized that I needed to switch the target label classification as mentioned eariler. It turns out I was measuring negative probabilities and I needed their complements. It made more sense after because the objective is to observe and predict cancellations. Making that the positive probabilities worked better in my favor. Once the adjustment was made, my AUC-ROC values were much more appealing and comprehensive.\n",
    "The next challenge was getting the AUC-ROC value to a desired number. My goal was to reach 0.85 before using the model on the test set. Scaling numerical data and including a new feature did not allow me to reach it exactly. I did, however, get it very close.\n",
    "## Key Ideas\n",
    "To solve this task, the most important thing is to make sense of what the values mean. Before testing the models, I needed to concat the datasets together. Since they were different sizes, I was left with many missing values. Some numerical data needed to be zero because it made sense in context (e.g. the total charges for people who just joined). Other Categorical data was given a string of 'N/A' because it indeed was not applicable. That allowed for a new category to be interpreted by the model for certain features. Without proper understanding of the given data, training would not have been accurate.\n",
    "## Final Model\n",
    "The final model that provided the best score was a CatBoost model. Specfically one that uses \"Logloss\" as its loss function and uses 120 iterations. Keep in mind that there was an added feature that was created by dividing the total charges by the monthly charges then rounded to the nearest whole number. The numerical data was then scaled with standard scaler.\n",
    "This model was tested on the test set and gave an AUC-ROC score of 0.845!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
